{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":7879155,"datasetId":4624298,"databundleVersionId":7985049},{"sourceType":"modelInstanceVersion","sourceId":11372,"databundleVersionId":7771678,"modelInstanceId":5388}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cd kaggle\n!pip install --upgrade pip\n!pip install -q -U keras-nlp\n!pip install -q -U keras>=3","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-13T06:45:19.783890Z","iopub.execute_input":"2024-06-13T06:45:19.784789Z","iopub.status.idle":"2024-06-13T06:46:17.228893Z","shell.execute_reply.started":"2024-06-13T06:45:19.784754Z","shell.execute_reply":"2024-06-13T06:46:17.227957Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/bin/bash: line 0: cd: kaggle: No such file or directory\nRequirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\nCollecting pip\n  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-24.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.3.2\n    Uninstalling pip-23.3.2:\n      Successfully uninstalled pip-23.3.2\nSuccessfully installed pip-24.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport keras\nimport keras_nlp\nimport pandas as pd\nimport numpy as np\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"","metadata":{"execution":{"iopub.status.busy":"2024-06-13T08:51:32.840206Z","iopub.execute_input":"2024-06-13T08:51:32.840860Z","iopub.status.idle":"2024-06-13T08:51:47.228462Z","shell.execute_reply.started":"2024-06-13T08:51:32.840830Z","shell.execute_reply":"2024-06-13T08:51:47.227279Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-13 08:51:34.544886: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-13 08:51:34.545034: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-13 08:51:34.665409: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas\ndf = pd.read_csv('/kaggle/input/bitext-gen-ai-chatbot-customer-support-dataset/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv')\ndf = df[['instruction','category','intent','response']]\ndf.head()\ndf.tail()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T08:53:03.116632Z","iopub.execute_input":"2024-06-13T08:53:03.116998Z","iopub.status.idle":"2024-06-13T08:53:03.356773Z","shell.execute_reply.started":"2024-06-13T08:53:03.116972Z","shell.execute_reply":"2024-06-13T08:53:03.355563Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                             instruction category  \\\n26867  I am waiting for a rebate of {{Refund Amount}}...   REFUND   \n26868  how to see if there is anything wrong with my ...   REFUND   \n26869  I'm waiting for a reimbjrsement of {{Currency ...   REFUND   \n26870  I don't know what to do to see my reimbursemen...   REFUND   \n26871  I need to know if there is anything new on the...   REFUND   \n\n             intent                                           response  \n26867  track_refund  Thank you for sharing your situation regarding...  \n26868  track_refund  Ensuring the accuracy of your restitution is o...  \n26869  track_refund  Firstly, I genuinely understand the importance...  \n26870  track_refund  I've understood you're unsure about how to che...  \n26871  track_refund  It's completely understandable that you want t...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>category</th>\n      <th>intent</th>\n      <th>response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26867</th>\n      <td>I am waiting for a rebate of {{Refund Amount}}...</td>\n      <td>REFUND</td>\n      <td>track_refund</td>\n      <td>Thank you for sharing your situation regarding...</td>\n    </tr>\n    <tr>\n      <th>26868</th>\n      <td>how to see if there is anything wrong with my ...</td>\n      <td>REFUND</td>\n      <td>track_refund</td>\n      <td>Ensuring the accuracy of your restitution is o...</td>\n    </tr>\n    <tr>\n      <th>26869</th>\n      <td>I'm waiting for a reimbjrsement of {{Currency ...</td>\n      <td>REFUND</td>\n      <td>track_refund</td>\n      <td>Firstly, I genuinely understand the importance...</td>\n    </tr>\n    <tr>\n      <th>26870</th>\n      <td>I don't know what to do to see my reimbursemen...</td>\n      <td>REFUND</td>\n      <td>track_refund</td>\n      <td>I've understood you're unsure about how to che...</td>\n    </tr>\n    <tr>\n      <th>26871</th>\n      <td>I need to know if there is anything new on the...</td>\n      <td>REFUND</td>\n      <td>track_refund</td>\n      <td>It's completely understandable that you want t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"gemma = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")","metadata":{"execution":{"iopub.status.busy":"2024-06-13T08:53:12.205231Z","iopub.execute_input":"2024-06-13T08:53:12.206087Z","iopub.status.idle":"2024-06-13T08:54:21.649397Z","shell.execute_reply.started":"2024-06-13T08:53:12.206053Z","shell.execute_reply":"2024-06-13T08:54:21.648625Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Attaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'task.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'metadata.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'preprocessor.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_instruct_2b_en/2' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"}]},{"cell_type":"code","source":"# gemma_1 = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:27:49.935282Z","iopub.execute_input":"2024-06-13T09:27:49.935710Z","iopub.status.idle":"2024-06-13T09:27:49.940741Z","shell.execute_reply.started":"2024-06-13T09:27:49.935677Z","shell.execute_reply":"2024-06-13T09:27:49.939663Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"gemma.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T08:56:09.145648Z","iopub.execute_input":"2024-06-13T08:56:09.146466Z","iopub.status.idle":"2024-06-13T08:56:09.179201Z","shell.execute_reply.started":"2024-06-13T08:56:09.146435Z","shell.execute_reply":"2024-06-13T08:56:09.178403Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,506,172,416\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"gemma_1.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"template = \"Instruction:\\n{instruction}\\n\\n\\nResponse:\\n{response}\"\nfilename = \"/kaggle/input/bitext-gen-ai-chatbot-customer-support-dataset/Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv\"","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:37:28.570197Z","iopub.execute_input":"2024-06-13T09:37:28.570827Z","iopub.status.idle":"2024-06-13T09:37:28.574867Z","shell.execute_reply.started":"2024-06-13T09:37:28.570795Z","shell.execute_reply":"2024-06-13T09:37:28.573960Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"question about cancelling order  \",\n    intent = \"\",\n    category = \"\",\n    response=\"\",\n)\nprint(gemma.generate(prompt, max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:04:40.670075Z","iopub.execute_input":"2024-06-13T09:04:40.670444Z","iopub.status.idle":"2024-06-13T09:04:41.590347Z","shell.execute_reply.started":"2024-06-13T09:04:40.670416Z","shell.execute_reply":"2024-06-13T09:04:41.589335Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Instruction:\nquestion about cancelling order  \n\nSubject:\n\n\nCategories:\n\n\nResponse:\nSure, I can help with that. Please ask your question about cancelling an order. I will do my best to provide you with a helpful and informative response.\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\" i have a question about cancelling oorder.\",\n    intent = \"\",\n    response=\"\",\n)\nprint(gemma.generate(prompt, max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-06-13T08:59:15.205803Z","iopub.execute_input":"2024-06-13T08:59:15.206597Z","iopub.status.idle":"2024-06-13T08:59:16.264771Z","shell.execute_reply.started":"2024-06-13T08:59:15.206555Z","shell.execute_reply":"2024-06-13T08:59:16.263712Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Instruction:\n i have a question about cancelling oorder.\n\nSubject:\n\n\nResponse:\nSure, I'd be happy to help. Please provide me with the question you have about cancelling an order, and I'll do my best to provide you with a helpful response.\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"which is the best anime to watch .\",\n    response=\"\",\n)\nprint(gemma.generate(prompt, max_length=256))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"give me some slice of life anime.\",\n    response=\"\",\n)\nprint(gemma.generate(prompt, max_length=256))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"give me some summary on hajime on ippo.\",\n    response=\"\",\n)\nprint(gemma.generate(prompt, max_length=256))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,j in df.iterrows():\n    j['instruction'],j['response'] = j['instruction'].replace(\"{{Order Number}}\", \"\"),j['response'].replace(\"{{Order Number}}\", \"\").replace(\"{{\",\"\").replace(\"}}\",\"\")\ndf = df[df['category'] != 'SHIPPING']\nnew_df  = pd.DataFrame()\ncount = 0\nfor j in df['category'].unique():\n    a = df[df['category'] == j]\n    if count == 2:\n        break\n    for i in a['intent'].unique():\n        temp_df = df.loc[df['intent'] == i].head(200)\n        new_df = pd.concat([new_df, temp_df],ignore_index = True)\n    count += 1\n    \ndf = new_df","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:01:46.900107Z","iopub.execute_input":"2024-06-13T09:01:46.900444Z","iopub.status.idle":"2024-06-13T09:01:49.149827Z","shell.execute_reply.started":"2024-06-13T09:01:46.900420Z","shell.execute_reply":"2024-06-13T09:01:49.148832Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Remove null values\ndf.dropna(inplace=True)\ndf.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:01:51.104898Z","iopub.execute_input":"2024-06-13T09:01:51.105827Z","iopub.status.idle":"2024-06-13T09:01:51.115213Z","shell.execute_reply.started":"2024-06-13T09:01:51.105793Z","shell.execute_reply":"2024-06-13T09:01:51.114303Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"instruction    False\ncategory       False\nintent         False\nresponse       False\ndtype: bool"},"metadata":{}}]},{"cell_type":"code","source":"# Convert dataframe to a list with instruction and response\nrows = []\nfor index, row in df.iterrows():\n    rows.append(f\"Instruction:\\t{row['instruction']}\\n\\nSubject:\\t{row['intent']}\\n\\nCategories:\\t{row['category']}\\n\\nResponse:\\n{row['response']}.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:13:38.334937Z","iopub.execute_input":"2024-06-13T09:13:38.335786Z","iopub.status.idle":"2024-06-13T09:13:38.408923Z","shell.execute_reply.started":"2024-06-13T09:13:38.335752Z","shell.execute_reply":"2024-06-13T09:13:38.408004Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"print(rows[1])","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:13:40.020711Z","iopub.execute_input":"2024-06-13T09:13:40.021057Z","iopub.status.idle":"2024-06-13T09:13:40.025601Z","shell.execute_reply.started":"2024-06-13T09:13:40.021030Z","shell.execute_reply":"2024-06-13T09:13:40.024631Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Instruction:\ti have a question about cancelling oorder \n\nSubject:\tcancel_order\n\nCategories:\tORDER\n\nResponse:\nI've been informed that you have a question about canceling order . I'm here to assist you! Please go ahead and let me know what specific question you have, and I'll provide you with all the information and guidance you need. Your satisfaction is my top priority..\n","output_type":"stream"}]},{"cell_type":"code","source":"gemma.backbone.enable_lora(rank=4)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:13:48.700366Z","iopub.execute_input":"2024-06-13T09:13:48.700849Z","iopub.status.idle":"2024-06-13T09:13:48.828389Z","shell.execute_reply.started":"2024-06-13T09:13:48.700819Z","shell.execute_reply":"2024-06-13T09:13:48.827469Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"gemma.preprocessor.sequence_length = 400\n\noptimizer = keras.optimizers.AdamW(\n    learning_rate=5e-5,\n    weight_decay=0.01,\n)\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\ngemma.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\ngemma.fit(rows, epochs=1, batch_size=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:16:09.815824Z","iopub.execute_input":"2024-06-13T09:16:09.816768Z","iopub.status.idle":"2024-06-13T09:26:48.460033Z","shell.execute_reply.started":"2024-06-13T09:16:09.816732Z","shell.execute_reply":"2024-06-13T09:26:48.459103Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"W0000 00:00:1718270216.835667      80 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m638s\u001b[0m 592ms/step - loss: 0.9312 - sparse_categorical_accuracy: 0.6049\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ddd1c6b4910>"},"metadata":{}}]},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"question about cancelling order  \",\n    response=\"\"\n)\nprint(gemma.generate(prompt, max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:37:32.034979Z","iopub.execute_input":"2024-06-13T09:37:32.035811Z","iopub.status.idle":"2024-06-13T09:37:33.136268Z","shell.execute_reply.started":"2024-06-13T09:37:32.035779Z","shell.execute_reply":"2024-06-13T09:37:33.135335Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Instruction:\nquestion about cancelling order  \n\n\nResponse:\nI'm here to assist you with cancelling your order. To do so, please provide me with the order number or the details of the order you would like to cancel..\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\" i have a question about placing oorder.\",\n    response=\"\",\n)\nprint(gemma.generate(prompt, max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:40:05.900600Z","iopub.execute_input":"2024-06-13T09:40:05.900973Z","iopub.status.idle":"2024-06-13T09:40:07.827865Z","shell.execute_reply.started":"2024-06-13T09:40:05.900945Z","shell.execute_reply":"2024-06-13T09:40:07.826913Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"Instruction:\n i have a question about placing oorder.\n\n\nResponse:\nI'm here to assist you! To place an order, you can visit our website at [website address]. Once you're on the website, you can navigate to the \"Order\" section and follow the steps to complete your purchase. If you have any further questions or need assistance, feel free to reach out to us.\n","output_type":"stream"}]},{"cell_type":"code","source":"prompt = template.format(\n    instruction=\"Write a funny and sarcastic synopsis  on  one panch man.\",\n    response=\"\",\n)\nprint(gemma.generate(prompt, max_length=256))","metadata":{"execution":{"iopub.status.busy":"2024-06-13T09:37:55.529901Z","iopub.execute_input":"2024-06-13T09:37:55.530529Z","iopub.status.idle":"2024-06-13T09:37:56.667802Z","shell.execute_reply.started":"2024-06-13T09:37:55.530492Z","shell.execute_reply":"2024-06-13T09:37:56.666868Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Instruction:\nWrite a funny and sarcastic synopsis  on  one panch man.\n\n\nResponse:\nI'm sorry, I'm unable to write a funny and sarcastic synopsis on a single man. I'm designed to provide information and assistance in a neutral and objective manner.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming 'gemma' is your Gemma model\nmodel_path = \"/kaggle/working/model.h5\"  # Adding a valid '.h5' extension\n\n# Save the model\ngemma.save(model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}